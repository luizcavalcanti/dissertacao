\chapter{Experimentos}\label{cap:experimentos}

\section{Base de dados}

A base de dados (imagens) utilizada advém do projeto GEOMA \cite{geoma}, financiado pelo Instituto de Pesquisas Espaciais (INPE). Trata-se de imagens coloridas, codificadas em JPEG e com 640 pixels de largura por 480 pixels de altura. A base é composta por fotografias ortogonais ao relevo (como pode ser visto na figura \ref{fig:amostra}), de altitudes variadas e tiradas a partir de aeronaves tripuladas, durante o trajeto entre diversas cidades da região amazônica.

No momento do início dos experimentos deste trabalho, estas imagens tiradas de aviões tripulados eram as únicas disponíveis publicamente. Podemos considerá-las válidas por terem sido tiradas em altitude de voo compatível com as missões de VANTs de vigilância, entre 900 e 1.100 metros do solo. Como este trabalho tem como objetivo utilizar apenas câmeras de espectro visível, são dispensáveis comparações de sensores com VANTs que eventualmente possuam sonar, câmeras infravermelho ou outros tipos de sensores.

\begin{figure}[h]
  \centering
  \begin{subfigure}[b]{0.3\textwidth}
    \includegraphics[width=\textwidth]{imgs/amostra1}
  \end{subfigure}%
  ~
  \begin{subfigure}[b]{0.3\textwidth}
    \includegraphics[width=\textwidth]{imgs/amostra2}
  \end{subfigure}%
  ~
  \begin{subfigure}[b]{0.3\textwidth}
    \includegraphics[width=\textwidth]{imgs/amostra3}
  \end{subfigure}%
  \caption{Amostras da base de dados}
  \label{fig:amostra}
\end{figure}

A base possui um total de 3.044 imagens, com dimensão total de 1,02 Gigabytes de dados. Todas as imagens foram utilizadas no presente trabalho sem tratamento ou manipulação prévios.

Para criar uma referência (\textit{ground-truth}) para a segmentação das imagens da base de dados, uma ferramenta computacional executável em navegadores web foi construída (figura \ref{fig:manualseg}). A saída deste aplicativo é uma coleção, para cada imagem, de informações sobre bordas das regiões da imagem. Estas informações servirão de referência para avaliar o desempenho dos algoritmos de segmentação testados neste trabalho.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.7\textwidth]{imgs/manualseg}
  \caption{Ferramenta para segmentação manual das imagens}
  \label{fig:manualseg}
\end{figure}

\section{Segmentação}

Um experimento de comparação entre diversos algoritmos de segmentação de imagens foi planejado. Cada imagem da base de dados foi segmentada por seres humanos, segmentações estas que constituíram a base de referência para o experimento. Cada imagem tem sua segmentação de referência consolidada a partir da segmentação manual de pelo menos 5 seres humanos.

\subsection{Protocolo experimental}

Para criação da segmentação manual de referência (\textit{ground-truth}), 31 voluntários, todos alunos de pós-graduação em informática ou áreas relacionadas, foram convidados a realizar a segmentação manual das imagens da base de dados, através de uma ferramenta\footnote{http://amazonsegmentation.ddns.net/} criada com esta finalidade. A ferramenta de software web criada consiste de uma interface gráfica onde o usuário pode desenhar sobre uma imagem a ser segmentada. A ideia é que nesta imagem sejam circunscritas as bordas das regiões definidas pelo usuário, de acordo com instruções fornecidas pela ferramenta e que foram lidas obrigatoriamente por cada voluntário antes do início do experimento.

Em linhas gerais, as instruções orientam os participantes no experimento a segmentar as imagens de acordo com a cobertura ou tipo de terreno, formação geológica ou vegetação, utilizando os critérios e granularidade que lhes pareçam mais adequados:

\begin{citacao}[english]
Your mission is to manually segment the given images as accurately as possible, according to your own judgment. The criteria here is terrain coverage. So, we would like to separate different vegetations, geological formations and human-made objects. \cite{amazonsegmentation}
\end{citacao}

Em tradução livre:

\begin{citacao}
Sua missão é segmentar manualmente as imagens disponibilizadas o mais precisamente possível, de acordo com o seu julgamento. O critério aplicado é a cobertura de terreno. Portanto, nós gostaríamos de separar diferentes vegetações, formações geológicas e objetos feitos por seres humanos. \cite{amazonsegmentation}
\end{citacao}

O conteúdo integral das instruções pode ser encontrado no apêndice \ref{apendice:instrucoesManualSeg}.

\subsection{Métricas}

%TODO Lugar certo? Talvez deva estar junto às métricas de avaliação de machine learning, na seção de fundamentação teórica, subseção de avaliação

Em primeiro lugar, é preciso aferir a validade da base de dados de segmentações manuais (\textit{ground-truth}), demonstrando que segmentações de uma mesma imagem feitas por diferentes indivíduos são consistentes. Em um segundo momento, é preciso avaliar os algoritmos de segmentação de forma objetiva.

O problema em mensurar a consistência entre duas segmentações é que não há uma única segmentação possível para uma imagem. Duas pessoas podem segmentar uma imagem de forma significativamente diferente por terem uma percepção diferente da cena, ou ainda, por usar diferentes granularidades na segmentação.

Quando a diferença entre duas segmentações advém de uma diferença de percepção da cena, é esperado que o erro seja grande e que as segmentações sejam consideradas inconsistentes. Quando a diferença é de granularidade, uma segmentação pode ser considerada apenas um refinamento da outra, portanto, o erro deve ser baixo ou até zero \cite{martin:2001}.

%TODO Adicionar uma imagem para demonstrar diferenças de granularidade?

Segmentação de imagens é simplesmente a divisão de pixels de uma imagem em conjuntos (segmentos). Uma possível medida de erro tem como entrada duas segmentações, $S_1$ e $S_2$, e tem como saída um valor real no intervalo $[0...1]$, onde $0$ significa ausência de erros de segmentação.

Ainda de acordo com o trabalho de \citeonline{martin:2001}, é necessário utilizar medidas que sejam lenientes com o refinamento de granularidade entre duas segmentações de uma mesma imagem. Entende-se que se os pixels de um segmento podem ser considerados um subconjunto adequado de um outro segmento, trata-se de um refinamento e o erro deve ser zero. Se não existe relação de subconjunto entre os segmentos, as regiões devem ser consideradas inconsistentes e o erro deve ser significativo.

Se $R(S,p_i)$ é o conjunto de pixels correspondentes a uma região na segmentação $S$ que contém o pixel $p_i$, onde $\setminus$ denota o conjunto complementar, o erro de refinamento local é definido por:

\begin{equation}
	E(S_1,S_2,p_i) = \frac{|R(S_1,p_i) \setminus R(S_2,p_i)|}{|R(S_1,p_i)|}
\end{equation}


A partir desta relação, \citeonline{martin:2001} define duas métricas de erro de segmentação: Erro de Consistência Global (Global Consistency Error, ou GCE) e Erro de Consistência Local (Local Consistency Error, ou LCE):

\begin{equation}
	GCE(S_1,S_2) = \frac{1}{n} min \biggl\{ \sum_{i} E(S_1,S_2,p_i), \sum_{i} E(S_2,S_1,p_i) \biggr\}
\end{equation}

\begin{equation}
	LCE(S_1,S_2) = \frac{1}{n} \sum_{i} min \biggl\{ E(S_1,S_2,p_i), E(S_2,S_1,p_i) \biggr\}
\end{equation}

Uma vez que $LCE \geq GCE$ entre segmentações de uma mesma imagem, é correto afirmar que $GCE$ é uma medida mais rígida que $LCE$. Além dos casos em que uma segmentação é um refinamento de outra, há ainda dois casos em que o erro de segmentação pode ser zero: quando os segmentos são compostos por apenas um pixel cada ou quando toda a imagem é composta de apenas um segmento.

\subsection{Resultados}

Antes de analisar o desempenho de cada algoritmo de segmentação presente neste trabalho em relação à segmentação manual, é preciso aferir a validade da própria segmentação manual, visto que ela foi realizada por diferentes participantes. Segundo \citeonline{martin:2001}, uma forma de validar a consistência das segmentações manuais é medir o erro entre segmentações de uma mesma imagem feita por diferentes pessoas.

Utilizando as métricas de erro de consistência local (LCE) e global (GCE) para medir a similaridade das segmentações manuais, os resultados confirmam a consisência da segmentação manual feira pelos participantes do experimento. Conforme pode ser visto nas figuras \ref{fig:manual_gce} e \ref{fig:manual_lce}, os coeficientes de erro global e local, respectivamente, ficam abaixo dos 20\% e 10\% para todos os casos.

\begin{figure}[h]
  \centering
  \begin{subfigure}[b]{0.5\textwidth}
    \includegraphics[width=\textwidth]{imgs/manual_gce}
  \end{subfigure}%
  ~
  \begin{subfigure}[b]{0.5\textwidth}
    \includegraphics[width=\textwidth]{imgs/manual_dist_gce}
  \end{subfigure}%
  \caption{Coeficiente de erro global das diferentes segmentações de mesma imagem}
  \label{fig:manual_gce}
\end{figure}

\begin{figure}[h]
  \centering
  \begin{subfigure}[b]{0.5\textwidth}
    \includegraphics[width=\textwidth]{imgs/manual_lce}
  \end{subfigure}%
  ~
  \begin{subfigure}[b]{0.5\textwidth}
    \includegraphics[width=\textwidth]{imgs/manual_dist_lce}
  \end{subfigure}%
  \caption{Coeficiente de erro local das diferentes segmentações de mesma imagem}
  \label{fig:manual_lce}
\end{figure}

Para determinar qual dos algoritmos de segmentação levantados na pesquisa bibliográfica teria melhor desempenho na base de dados utilizada neste trabalho, todos foram implementados ou adaptados. Os algoritmos foram testados em todas as imagens da base de dados do trabalho que possuíam segmentação manual por pelo menos 5 voluntários, um total de 203 imagens, utilizando as mesmas medidas de erro global (GCE) e erro local (LCE) apresentados no trabalho de \citeonline{martin:2001} e na validação da base de segmentação manual construída para este trabalho.

Os resultados do experimento são apresentados na tabela \ref{tab:experimentoSegmentacao}:

\begin{table}[h]
\ABNTEXfontereduzida
\centering
\begin{tabulary}{\linewidth}{|L|R|R|R|}
\hline
\textbf{Algoritmo} & \textbf{GCE médio} & \textbf{LCE médio} & \textbf{Tempo (s)} \\ \hline
Manual      & 0.01822          & 0.00537         & - \\ \hline
FSEG        & 0.03063          & 0.00273         & 13,91 \\ \hline
gPb-owt-ucm & 0.00655          & 0.00297         & 237,32 \\ \hline
JSEG        & 0.02990          & 0.00486         & 14,82 \\ \hline
Mean-shift  & 0.02237          & 0.00271         & 6,39 \\ \hline
MSEG        & 0.01005          & 0.00072         & \cellcolor{gray!25} 0,33 \\ \hline
SRM         & \cellcolor{gray!25} 0.00622 & \cellcolor{gray!25} 0.0066 & 4,66 \\ \hline
\end{tabulary}
\caption{Comparação de métodos de segmentação em parte da base de imagens deste trabalho, em ordem alfabética}
\label{tab:experimentoSegmentacao}
\end{table}

O método SRM conseguiu uma média de erros global e local substancialmente menor que os demais algoritmos e foi considerado o método com melhor desempenho do experimento na base de imagens deste trabalho, embora o tempo de segmentação deste algoritmo seja uma ordem de magnitude maior que o algoritmo MSEG, que obteve o melhor tempo de execução. A imagem \ref{fig:comparacaoSegmentacao} mostra a saída de alguns dos métodos testados, para fins de comparação visual.

\begin{figure}[htb]
	\centering
	\begin{minipage}[l]{0.32\linewidth}
		\begin{subfigure}[b]{\linewidth}
			\includegraphics[width=\linewidth]{imgs/seg_original}
			\caption{Imagem original}
		\end{subfigure}%
	\end{minipage}
	\begin{minipage}[r]{\linewidth}
		\begin{subfigure}{.32\linewidth}
			\includegraphics[width=\linewidth]{imgs/seg_meanshift}
			\caption{Mean-shift}
		\end{subfigure}
		\begin{subfigure}{.32\linewidth}
			\includegraphics[width=\linewidth]{imgs/seg_mseg}
			\caption{MSEG}
		\end{subfigure}
		\begin{subfigure}{.32\linewidth}
			\includegraphics[width=\linewidth]{imgs/seg_jseg}
			\caption{JSEG}
		\end{subfigure}
	\end{minipage}
	\begin{minipage}[r]{\linewidth}
		\begin{subfigure}{.32\linewidth}
			\includegraphics[width=\linewidth]{imgs/seg_srm}
			\caption{SRM}
		\end{subfigure}
		\begin{subfigure}{.32\linewidth}
			\includegraphics[width=\linewidth]{imgs/seg_gpb}
			\caption{gPb-owt-ucm}
		\end{subfigure}
		\begin{subfigure}{.32\linewidth}
			\includegraphics[width=\linewidth]{imgs/seg_fseg}
			\caption{FSEG}
		\end{subfigure}%
	\end{minipage}
	\caption{Comparação visual de métodos de segmentação}
	\label{fig:comparacaoSegmentacao}
\end{figure}


Adicionalmente, experimentos foram realizados com técnicas de classificação. O objetivo era saber se poderíamos utilizar apenas uma etapa para realizar segmentação e o primeiro nível de classificação. Os resultados foram abaixo do que se consegue na etapa de segmentação isolada. Os resultados foram publicados no \textit{$10^th$ International Conference on Computer Vision Theory and Applications} e o artigo \cite{cavalcanti:2015} completo pode ser visto no apêndice \ref{cap:visapp2015}.

Para fins de comparação, os resultados deste segundo experimento são apresentados na tabela \ref{tab:experimentoArtigo}. O tempo de execução da classificação para cada imagem no artigo publicado ignora o tempo de extração de características da imagem. Para uma comparação correta com os métodos de segmentação experimentados anteriormente, esse tempo gasto em extração de características foi acrescido na tabela desta seção.

\begin{table}[h]
\ABNTEXfontereduzida
\centering
\begin{tabulary}{\linewidth}{|L|R|R|}
\hline
\textbf{Algoritmo} & \textbf{Acurácia} & \textbf{Tempo/imagem} \\ \hline
Random forest  & \cellcolor{gray!25} 96,0\% & 12,72 s \\ \hline
KNN            & 92,6\%                     & 22,89 s \\ \hline
Naive Bayes    & 92,8\%                     & \cellcolor{gray!25} 8,36 s \\ \hline
Decision tree  & 82,2\%                     & 14,49 s \\ \hline
\end{tabulary}
\caption{Comparação de métodos de classificação para segmentação das imagens em uma única etapa, ordenados por acurácia}
\label{tab:experimentoArtigo}
\end{table}

Os segmentos encontrados pelo algoritmo SRM, escolhido nesta etapa, serviram de entrada para a próxima etapa da solução, responsável pela classificações destes mesmos segmentos.

\section{Classificações de regiões}

Para o primeiro nível de classificação, que se resume a definir os tipos de terrenos das regiões encontradas na segmentação, um experimento utilizando métodos bastante difundidos de aprendizagem de máquina foi realizado.

\subsection{Protocolo experimental}

Utilizando as técnicas de K vizinhos mais próximos (KNN), máquinas de vetores de suporte (SVM), árvores de decisão e \textit{Random Forest}, um experimento foi conduzido com o intuito de classificar os segmentos de imagem gerados na etapa anterior do trabalho e definir que método mais se adequa para a solução do problema proposto neste trabalho.

Primeiramente, todas as imagens foram segmentadas utilizando o algoritmo SRM, por conta de seu melhor desempenho no experimento de segmentação anterior. Cada um dos 10.057 segmentos produzidos nesta segmentação foi devidamente classificada manualmente, e suas características foram extraídas. Cada segmento foi classificado como uma das possíveis classes para o problema: floresta, vegetação rasteira, água, terra ou elemento antrópico.

Alguns segmentos não puderam ser classificados e foram descartados das bases de treinamento e validação. Todos os elementos antrópicos encontrados foram validados pela Dra. Solange Costa, especialista do Centro Gestor e Operacional do Sistema de Proteção da Amazônia (CENSIPAM), órgão governamental federal responsável pelo patrulhamento e sensoriamento remoto da Amazônia legal brasileira.

A partir desse ponto o conjunto total de segmentos foi dividido entre um conjunto de treinamento e um conjunto de validação, com 66\% e 34\% das amostras respectivamente.

Em seguida, uma análise da base de segmentos rotulada é feita, observando a estrutura e distribuição dos dados ao longo de toda a base, levando em consideração como os tipos de dados utilizados e sua representação podem influenciar os resultados dos algoritmos de aprendizado utilizados no experimento.

Finalmente, todos os algoritmos processam os conjuntos de treinamento para criar um modelo de aprendizado e em seguida, utilizam a base de validação para medir o quanto o modelo pode ser generalizado para bases de imagens diferentes. Cada algoritmos testado será refinado e parametrizado para que consiga uma maior acurácia para todas as classes e que a revocação seja otimizada para a classe de "elementos antrópicos".

\subsection{Resultados}

O vetor de características escolhido para representar cada amostra compreende informações de cor, intensidade, morfologia e textura de cada segmento a ser classificado. Este conjunto de características foi escolhido pela alta representatividade de valores em determinadas classes, baixa dimensionalidade e simples depuração.

A Cor média para os canais vermelho, verde e azul de todo o segmento trazem informação do tom de cor, enquanto a intensidade média e o histograma em tons de cinza ajudam a representar informações de intensidade. Para guardar informações sobre a textura e variância de intensidade do segmento, um histograma de \textit{Local Binary Pattern}, descrito por \citeonline{ahonen:2009}, foi extraído.

Finalmente, para tentar representar características de morfologia do segmento, a transformada de Hough é utilizada. Neste último conjunto de características, a contagem de linhas retas e o comprimento da maior linha são utilizados.

Com a discretização e normalização das variáveis que compõem o vetor de características, temos um total de 48 atributos numéricos. Um total de 10.057 amostras foram classificadas, onde 6.638 (66\%) foram utilizadas como amostras de treinamento e 3.419 (34\%) foram utilizadas como amostras de validação.

A lista de atributos, seus tipos, dimensões e unicidade (singularidade) podem ser vistos na tabela \ref{tab:experimentoClassificacao1Atributos}.

\begin{table}[h]
\ABNTEXfontereduzida
\centering
\begin{tabulary}{\linewidth}{|L|L|R|}
\hline
\textbf{Atributo} & \textbf{Tipo} & \textbf{Dimensão} \\ \hline
Vermelho médio            & Real    &  1x1 \\ \hline
Verde médio               & Real    &  1x1 \\ \hline
Azul médio                & Real    &  1x1 \\ \hline
Intensidade média         & Real    &  1x1 \\ \hline
Intensidade - histograma  & Inteiro & 16x1 \\ \hline
LBP - histograma          & Inteiro & 26x1 \\ \hline
Hough - número de retas   & Inteiro &  1x1 \\ \hline
Hough - maior reta        & Inteiro &  1x1 \\ \hline
\end{tabulary}
\caption{Atributos gerados a partir da base de segmentos}
\label{tab:experimentoClassificacao1Atributos}
\end{table}


A distribuição das classes na base de segmentos, após a rotulação de todas as amostras, pode ser vista na tabela \ref{tab:experimentoRegioesDistribuicao}.

\begin{table}[h]
\ABNTEXfontereduzida
\centering
\begin{tabulary}{\linewidth}{|L|R|R|}
\hline
\textbf{Classe} & \textbf{Amostras} & \textbf{Percentual} \\ \hline
Floresta             & 8.684 & 86,3 \% \\ \hline
Vegetação rasteira   &   939 &  9,3 \% \\ \hline
Água                 &   287 &  2,8 \% \\ \hline
Terra/areia/barro    &   136 &  1,3 \% \\ \hline
Elementos antrópicos &    31 &  0,3 \% \\ \hline
\end{tabulary}
\caption{Distribuição de classes na base de segmentos}
\label{tab:experimentoRegioesDistribuicao}
\end{table}

%TODO falar dos problemas da base desbalanceada e do que foi feito para resolver
%TODO falar da seleção de atributos
%TODO fazer bruteforce para encontar melhores métodos/parametros

\begin{table}[h]
\ABNTEXfontereduzida
\centering
	\begin{tabulary}{\linewidth}{|L|R|R|R|}
		\hline
		\textbf{Método} & \textbf{Acurácia} & \textbf{Precisão} & \textbf{Revocação} \\ \hline
		Random Forest     & 92,70\% & 0.939 & 0.926 \\ \hline
		KNN (3)           & 92,26\% & 0.920 & 0.922 \\ \hline
		SVM               & 91,27\% & 0.899 & 0.913 \\ \hline
		Árvore de decisão & 90,21\% & 0.907 & 0.902 \\ \hline
	\end{tabulary}
\caption{Comparação de métodos de classificação para regiões segmentadas das imagens, ordenados por acurácia}
\label{tab:experimentoClassificacao1}
\end{table}

\section{Detecção de elementos antrópicos}

\subsection{Protocolo experimental}

%TODO falar do tamanho da base gerada
%TODO falar da inserção artificial de elementos antrópicos
%TODO falar do atributos extraídos para cada tipo de terreno

\subsection{Resultados}

%TODO expor resultados para cada tipo de terreno