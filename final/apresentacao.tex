\PassOptionsToPackage{table}{xcolor}
\documentclass[t]{beamer}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[brazil]{babel}
\usepackage[round,authoryear]{natbib}
\usepackage{tabulary}
\usepackage{multicol}
\usepackage[table]{xcolor}
\usepackage{gensymb}
\usepackage{multicol}

%%%% TEMAS %%%%
%\usetheme{Antibes}
%\usetheme{Bergen}
%\usetheme{Berkeley}
%\usetheme{Berlin}
%\usetheme{Copenhagen}
%\usetheme{Darmstadt}
%\usetheme{Dresden}
%\usetheme{Frankfurt}
%\usetheme{Goettingen}
%\usetheme{Hannover}
%\usetheme{Ilmenau}
%\usetheme{JuanLesPins}
%\usetheme{Luebeck}
%\usetheme{Madrid}
%\usetheme{Malmoe}
%\usetheme{Marburg}
%\usetheme{Montpellier}
%\usetheme{PaloAlto}
%\usetheme{Pittsburgh}
%\usetheme{Rochester}
\usetheme{Singapore}
%\usetheme{Szeged}
%\usetheme{Warsaw}
%\usetheme{boxes}
%\usetheme{default}
%\usetheme{CambridgeUS}

%%%% CORES %%%%

\usecolortheme{default}
%\usecolortheme{albatross}
%\usecolortheme{beaver}
%\usecolortheme{beetle}
%\usecolortheme{crane}
%\usecolortheme{dolphin}
%\usecolortheme{dove}
%\usecolortheme{fly}
%\usecolortheme{lily}
%\usecolortheme{orchid}
%\usecolortheme{rose}
%\usecolortheme{seagull}
%\usecolortheme{seahorse}
%\usecolortheme{whale}
%\usecolortheme{wolverine}

%%%% TITULO %%%%
\institute[Universities Here and There] % (optional)
{
  Programa de Pós-graduação em Informática\\
  Instituto de Computação\\
  Unversidade Federal do Amazonas
}
\title % (optional, only for long titles)
{Detecção de elementos antrópicos em imagens aéreas da floresta amazônica}
%\subtitle{Evidence from India}
\author %[Author, Anders] % (optional, for multiple authors)
{Luiz Carlos A. M. Cavalcanti
\\Orientadora: Dr$^a$ Eulanda Miranda dos Santos} %\inst{1}}
\date[] % (optional)
{}
\subject{Computer Science}

\AtBeginSection[]
{
  \begin{frame}
    \frametitle{Roteiro}
    \tableofcontents[currentsection]
  \end{frame}
}

\begin{document}
  \begin{frame}\titlepage\end{frame}

%%%%%%%%%%%%%%%

\section{Contextualização}

\begin{frame}[c]
\frametitle{Introdução}
	Amazônia legal:
	\begin{itemize}
		\item 11 mil km de fronteiras;
		\item 22 mil km de vias fluviais;
		\item 66\% do território nacional.
	\end{itemize}

	\vspace{0.5cm}

	VANTs podem ser utilizados no patrulhamento:
	\begin{itemize}
		\item Diminuição do risco humano;
		\item Maior cobertura de área;
		\item Aproximação discreta;
		\item Variedade de sensores embarcados.
	\end{itemize}
\end{frame}

\begin{frame}[c]
\frametitle{Motivação}

A quantidade maciça de dados gerados pelos VANTs leva à necessidade de desenvolvimento de procedimentos capazes de avaliar essa grande quantidade de material e identificar os prováveis objetos de interesse.

\begin{itemize}
	\item Maior rapidez na análise de dados;
	\item Redução da quantidade de informação a analizar;
	\item Necessidade de menos especialistas por missão.
\end{itemize}

Objetos de interesse:
\begin{itemize}
	\item Veículos terrestres e navais;
	\item Acampamentos, construções;
	\item Clareiras, pistas de pouso, estradas.
\end{itemize}


%Técnicas de PDI e AM podem ajudar a encontrar:

\end{frame}

\begin{frame}[c]
\frametitle{Objetivos}

\textbf{Geral:}

\begin{itemize}
	\item Propor uma abordagem utilizando PDI e AM para detecção automática de elementos antrópicos em imagens aéreas da floresta amazônica.
\end{itemize}

\textbf{Específicos:}

\begin{itemize}
    \item Organizar uma base de imagens devidamente rotuladas que sirva de referência para futuros estudos desta problemática;
    \item Investigar e definir métodos para segmentação de imagens aéreas da floresta amazônica;
    \item Investigar e definir métodos para extração e seleção de características mais adequadas ao problema em questão.
    \item Apontar o melhor conjunto de técnicas para a detecção de elementos antrópicos em imagens aéreas da floresta amazônica.
\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%

\section{Trabalhos relacionados}

\begin{frame}[c]
	\frametitle{Trabalhos relacionados}

	O trabalho se propõe a utilizar técnicas de PDI e AM, portanto o levantamento bibliográfico foi dividido entre essas duas áreas de pesquisa, com os temas centrais:
	\vspace{0.5cm}
	\begin{itemize}
		\item Segmentação de imagens;
		\item Classificação de imagens aéreas;
		\item Detecção de anomalias.
	\end{itemize}
\end{frame}

\begin{frame}[c]
	\frametitle{Trabalhos relacionados: Segmentação de imagens}

	\vspace{.5cm}

	\textbf{\textit{Berkeley Segmentation Dataset 500} (BSD500)}
	
	\textit{Arbelaez et al. (2011)}
	
	\vspace{.5cm}
		
	Conjunto de 500 imagens naturais. Todas as imagens possuem \textit{ground truth} de segmentação por seres humanos.
	
	\vspace{.5cm}
	
	Uma importante base de imagens naturais para comparação entre algoritmos de segmentação.

\end{frame}

\begin{frame}[c]
	\frametitle{Trabalhos relacionados: Segmentação de imagens}

	\vspace{.5cm}

	\textbf{Systematic benchmarking of aerial image segmentation}

	\textit{Yuan, Gleason e Cheriyadat (2013)}

	\vspace{.5cm}

	Revisão dos algoritmos mais bem sucedidos na BSD500, utilizando uma nova base de imagens, composta apenas de imagens aéreas.

	\small{
	\begin{table}[h]
	\centering
	\begin{tabulary}{\linewidth}{|L|L|C|C|}
	\hline
	\textbf{Técnica} & \textbf{Características} & \textbf{Pr. bordas} & \textbf{Pr. regiões } \\ \hline
	Manual      & \hspace{1cm} -       & 69\% & 84\% \\ \hline
	\cellcolor{gray!25} gPb-owt-ucm & \cellcolor{gray!25} Brilho, cor, textura & \cellcolor{gray!25} 65\% & \cellcolor{gray!25} 69\% \\ \hline
	FSEG        & Textura              & 61\% & 66\% \\ \hline
	SRM         & Cor, intensidade     & 60\% & 60\% \\ \hline
	JSEG        & Cor, borda           & 56\% & 66\% \\ \hline
	MSEG        & Cor, morfologia      & 57\% & 50\% \\ \hline
	Mean-shift  & Cor, posição         & 58\% & 48\% \\ \hline
	\end{tabulary}
	\end{table}
	}
\end{frame}

%\begin{frame}
%	\frametitle{Trabalhos relacionados: Segmentação de imagens}
%
%	\vspace{0.2cm}
%
%	\textbf{Unsupervised segmentation of color-texture regions in images and video}
%
%	\textit{Deng e Manjunath (2001)}
%	
%	\begin{figure}[h]
%  		\centering
%		\includegraphics[scale=0.25]{imgs/demo_jseg}
%	\end{figure}
%
%	Descreve o algoritmo JSEG, que segmenta a imagem em duas etapas:
%	\begin{enumerate}
%		\item Quantização das cores em diversas classes;
%		\item Computação de um limiar ($J$) para determinar as bordas a partir das cores quantizadas.
%	\end{enumerate}
%
%	As regiões são obtidas a partir de crescimento de região com base no valor de $J$.
%
%\end{frame}

%\begin{frame}
%	\frametitle{Trabalhos relacionados: Segmentação de imagens}
%
%	\textbf{Mean shift: a robust approach toward feature space analysis}
%
%	\textit{Comaniciu e Meer (2002)}
%
%	\vspace{0.5cm}
%
%	O algoritmo computa vetores de mean-shift iterativamente para mapear pixels para o domínio espacial e de cores do centro de seus \textit{clusters}. Após a convergência, os \textit{clusters} são fundidos de acordo com parâmetros de similaridade. 
%
%	\vspace{0.5cm}
%
%	Parâmetros como largura de banda espacial, de cores e o tamanho do menor \textit{cluster} podem ser utilizados para adequar o algoritmo ao problema em questão.
%
%\end{frame}

%\begin{frame}
%	\frametitle{Trabalhos relacionados: Segmentação de imagens}
%
%	\textbf{Efficient graph-based image segmentation}
%
%	\textit{Felzenszwalb e Huttenlocher (2004)}
%
%	\vspace{0.5cm}
%
%	O algoritmo MSEG é amplamente usado pela comunidade de sensoriamento remoto.
%
%	\vspace{0.5cm}
%
%	Sob a óptica de grafos, os pixels são tratados como nodos e os pesos de suas arestas representam a diferença entre características entre os pixels. Um segmento corresponde a um componente conectado.
%\end{frame}
%
%\begin{frame}
%	\frametitle{Trabalhos relacionados: Segmentação de imagens}
%
%	\textbf{Statistical region merging}
%
%	\textit{Nock e Nielsen (2004)}
%
%	\vspace{0.5cm}
%
%	O algoritmo SRM utiliza um procedimento simples de junção acompanhado por uma operação de ordenação para segmentar imagens com eficiência. Duas regiões são unidas se a diferença entre os valores médios dos pixels das duas regiões estão abaixo de um limiar. 
%
%	\vspace{0.5cm}
%
%	A coesão da segmentação pode ser controlada por um parâmetro definido pelo usuário.
%
%\end{frame}
%
%\begin{frame}
%	\frametitle{Trabalhos relacionados: Segmentação de imagens}
%
%	\textbf{Contour Detection and Hierarchical Image Segmentation}
%
%	\textit{Arbelaez et al. (2011)}
%
%	\vspace{0.5cm}
%
%	O algoritmo gPb-owt-ucm realiza segmentação em várias etapas. Primeiramente a técnica combina informações de intensidade, textura e coloração para computar vetores que servirão como detectores de contorno. Posteriormente, uma técnica de \textit{watershed} é aplicada à saída do detector de contornos para produzir uma segmentação hierárquica da imagem.
%
%\end{frame}
%
%\begin{frame}
%	\frametitle{Trabalhos relacionados: Segmentação de imagens}
%
%	\textbf{Factorization-based texture segmentation}
%
%	\textit{Yuan e Wang (2013)}
%
%	\vspace{0.5cm}
%
%	O FSEG primeiramente computa o histograma espectral para cada pixel da imagem. A proposta é que cada característica pode ser aproximada por uma combinação linear de diversas características representativas e suas combinações ponderadas. 
%
%	\vspace{0.5cm}
%
%	Por fim, um pixel é dito pertencente à região com maior peso. O algoritmo FSEG utiliza decomposição de valores singulares e fatoração de matrizes não-negativas para aumentar a eficiência computacional da segmentação.
%
%\end{frame}
%
%\begin{frame}
%	\frametitle{Trabalhos relacionados: Segmentação de imagens}
%
%	Resultados em \textbf{Yuan, Gleason e Cheriyadat (2013)}:
%
%	\small{
%	\begin{table}[h]
%	\centering
%	\begin{tabulary}{\linewidth}{|L|L|C|C|}
%	\hline
%	\textbf{Técnica} & \textbf{Características} & \textbf{Prec. bordas} & \textbf{Prec. regiões } \\ \hline
%	Manual      & \hspace{1cm} -    & 69\% & 84\% \\ \hline
%	gPb-owt-ucm & Cor, borda       & 65\% & 69\% \\ \hline
%	FSEG        & Textura          & 61\% & 66\% \\ \hline
%	SRM         & Cor, intensidade & 60\% & 60\% \\ \hline
%	JSEG        & Cor, borda       & 56\% & 66\% \\ \hline
%	MSEG        & Cor, morfologia  & 57\% & 50\% \\ \hline
%	Mean-shift  & Cor, posição     & 58\% & 48\% \\ \hline
%	\end{tabulary}
%	\end{table}
%	}
%
%\end{frame}

\begin{frame}[c]
	\frametitle{Trabalhos relacionados: Classificação de imagens aéreas}

	Os trabalhos levantados acerca desta seção tratam de classificação de imagens aéreas para fins de mapeamento ou detecção de características específicas. 

	\vspace{0.5cm}

	Os trabalhos foram selecionados por estar de acordo com as seguintes características das imagens utilizadas:

	\begin{itemize}
		\item Cenas naturais;
		\item Forte presença de vegetação.
 		\item Ortogonais ao solo ou inclinadas à aproximadamente 90\degree;
	\end{itemize}
\end{frame}

%\begin{frame}
%	\frametitle{Trabalhos relacionados: Classificação de imagens aéreas}
%
%	\textbf{Color and texture fusion: application to aerial image segmentation and GIS updating}
%
%	\textit{Dubuisson-Jolly e Gupta (2000)}
%
%	\vspace{0.5cm}
%
%	Apresenta uma técnica de segmentação focada em imagens aéreas coloridas que realiza a segmentações separadamente por cor e textura, para no final unir as duas e chegar a uma segmentação final utilizando um algoritmo de classificação por \textit{Maximum Likelihood}.
%
%\end{frame}
%
%\begin{frame}
%	\frametitle{Trabalhos relacionados: Classificação de imagens aéreas}
%
%	\textbf{Aerial image processing and object recognition}
%
%	\textit{Sadgal, Fazziki e Ouahman (2005)}
%
%	\vspace{0.5cm}
%
%	Sugere pré-processamento, segmentação e reconhecimento em uma única etapa. Combina métodos estocásticos (inferência Bayesiana, campos de Markov) e não-estocásticos (redes neurais).
%
%	\vspace{0.5cm}
%
%	Métodos são unidos no final do processo, permitindo parelelização de boa parte da solução.
%
%\end{frame}
%
%\begin{frame}
%	\frametitle{Trabalhos relacionados: Classificação de imagens aéreas}
%
%	\textbf{A simple and efficient method for segmentation and classification of aerial images}
%
%	\textit{Ahmadi (2013)}
%
%	\vspace{0.5cm}
%
%	Utiliza características de cor (HSV) e textura (filtro de Gabor) e KNN para  realizar classificação de tipos de terreno em imagens aéreas.
%
%\end{frame}
%
%\begin{frame}
%	\frametitle{Trabalhos relacionados: Classificação de imagens aéreas}
%
%	\textbf{Fast semantic segmentation of aerial images based on color and texture}
%
%	\textit{Ghiasi e Amirfattahi (2013)}
%
%	\vspace{0.5cm}
%
%	Realiza segmentação e classificação de tipos de terreno em imagens aéreas.
%
%	\vspace{0.5cm}
%
%	A imagem é dividida em superpixels (fluxos geométricos de Levishtein) e características de cor (RGB) e textura (LBP-HF) são extraídas. Cada superpixel é classificado com KNN.
%
%\end{frame}
%
%\begin{frame}
%	\frametitle{Trabalhos relacionados: Classificação de imagens aéreas}
%
%	FERNANDES
%
%\end{frame}
%
%\begin{frame}
%	\frametitle{Trabalhos relacionados: Classificação de imagens aéreas}
%
%	MUNOZ-MARI
%
%\end{frame}

\begin{frame}[c]
	\frametitle{Trabalhos relacionados: Classificação de imagens aéreas}
	\small{
		\begin{table}[h]
		\centering
		\begin{tabulary}{\linewidth}{|L|L|L|L|C|}
		\hline
		\textbf{Trabalho} &  \textbf{Aprendizado} & \textbf{Problema investigado} &  \textbf{Acurácia} \\ \hline
		Dub-Jolly  & Máxima veross. & Atualização de mapas      & 91,8\%  \\ \hline
		Sadgal     & Redes neurais  & Classificação de terreno  & -       \\ \hline
		Munoz-Mari & Class. unários & Det. de áreas urbanas     & 97,2\%  \\ \hline
		Fernandes  & SVM            & Det. de desmatamento      & 87,0\%  \\ \hline
		Ahmadi     & KNN            & Classificação de terreno  & 82,2\% \\ \hline
		Ghiasi     & KNN            & Busca por objetos         & 95,0\%  \\ \hline
		\end{tabulary}
		\end{table}
	}
\end{frame}


\begin{frame}[c]
	\frametitle{Trabalhos relacionados: Detecção de anomalias}

	\vspace{0.5cm}

	Os trabalhos levantados acerca desta seção tratam de utilização de aprendizagem de máquina com métodos unários para encontrar outliers em imagens.
	
	\vspace{0.5cm}

	\small{
		\begin{table}[h]
		\begin{tabulary}{\linewidth}{|L|L|L|R|}
			\hline
			\textbf{Trabalho} & \textbf{Aprendizado} & \textbf{Problema investigado} & \textbf{Acurácia} \\ \hline
			Hegenbart & OC-SVM & Diagnóstico médico       & 82,9\% \\ \hline
			Pla       & OC-SVM & Det. de vegetação        & -      \\ \hline
			Wang      & SCSVDD & Det. de objetos incomuns & 94,0\% \\ \hline
		\end{tabulary}
		\end{table}
	}
\end{frame}

%\begin{frame}
%	\frametitle{Trabalhos relacionados: Detecção de anomalias}
%
%	Hegenbart
%
%\end{frame}

%\begin{frame}
%	\frametitle{Trabalhos relacionados: Detecção de anomalias}
%
%	Pla
%
%\end{frame}

%\begin{frame}
%	\frametitle{Trabalhos relacionados: Detecção de anomalias}
%
%	Wang
%
%\end{frame}

%%%%%%%%%%%%%%%

\section{Metodologia}

\begin{frame}[c]
	\frametitle{Metodologia: Arquitetura geral}
	\begin{figure}[h]
    	\includegraphics[width=\textwidth]{imgs/arquitetura_geral}
	\end{figure}
\end{frame}

\begin{frame}[c]
	\frametitle{Metodologia: Entrada}
	\begin{figure}[h]
    	\includegraphics[width=\textwidth]{imgs/arquitetura_1}
	\end{figure}
\end{frame}

\begin{frame}[c] 
	\frametitle{Metodologia: Entrada}
	
	Imagens aéreas da floresta amazônica serão a entrada para a solução. Todas as imagens serão coloridas, com 24 bits de profundidade de cores.

	\vspace{0.5cm}

	Não é esperado qualquer tipo de tratamento ou filtragem prévia das imagens.
\end{frame}

\begin{frame}[c]
	\frametitle{Metodologia: Segmentador}
	\begin{figure}[h]
    	\includegraphics[width=\textwidth]{imgs/arquitetura_2}
	\end{figure}
\end{frame}

\begin{frame}[c]

	\frametitle{Metodologia: Segmentador}

	Uma parcela da base de imagens será manualmente segmentada por seres humanos e servirá de \textit{ground-truth} para a segmentação realizada pelos métodos experimentados.

	\vspace{0.5cm}

	As taxas de erro de consistência local (LCE) e global (GCE) [Martin et al., 2001] serão utilizados para aferir a qualidade da segmentação.

	\begin{equation*}
		\displaystyle GCE(S_1,S_2) = \frac{1}{n} min \biggl\{ \sum_{i} E(S_1,S_2,p_i), \sum_{i} E(S_2,S_1,p_i) \biggr\}
	\end{equation*}

	\begin{equation*}
		\displaystyle LCE(S_1,S_2) = \frac{1}{n} \sum_{i} min \biggl\{ E(S_1,S_2,p_i), E(S_2,S_1,p_i) \biggr\}
	\end{equation*}
\end{frame}

\begin{frame}[c]
	\frametitle{Metodologia: Extrator}
	\begin{figure}[h]
    	\includegraphics[width=\textwidth]{imgs/arquitetura_3}
	\end{figure}
\end{frame}

\begin{frame}[c]

	\frametitle{Metodologia: Extrator}

	Nesta etapa serão extraídas informações sobre cor, intensidade, textura e morfologia das imagens. A escolha das características foi baseada nas utilizadas em trabalhos relacionados: 
	
	\begin{itemize}
		\item Canais de cores (RBG, HSV)
		\item Histogramas de intensidade
		\item \textit{Local Binary Patterns}
		\item Transformada de Hough
	\end{itemize}
\end{frame}

\begin{frame}[c]

	\frametitle{Metodologia: Extrator}

	O algoritmo de seleção de características CFS será utilizado, e os resultados comparados ao conjunto total de características.

	\vspace{0.5cm}

	\begin{equation*}
		\displaystyle p(C=c|V_i=v_i) \neq p(C=c)
	\end{equation*}

	\vspace{0.5cm}

	Todas as amostras serão rotuladas manualmente, a fim de compor a base de dados de segmentos a ser classificada.
\end{frame}

\begin{frame}[c]
	\frametitle{Metodologia: Classificador}
	\begin{figure}[h]
    	\includegraphics[width=\textwidth]{imgs/arquitetura_4}
	\end{figure}
\end{frame}

\begin{frame}[c]
	\frametitle{Metodologia: Classificador}
	
	Quatro abordagens de classificação:
	\begin{itemize}
		\item Multiclasse;
		\item Biclasse;
		\item Unária;
		\item Conjunto de unários.
	\end{itemize}

	\vspace{0.5cm}

	A motivação é a diversidade de estratégias encontradas na literatura e a falta de um trabalho que sirva de baseline.
\end{frame}

\begin{frame}[c]
	\frametitle{Metodologia: Classificador}

	Todos os experimentos serão realizados com e sem seleção de características através do método CFS.

	\vspace{0.5cm}

	Para comparação dos resultados de classificação, os valores de precisão, revocação e medida F1 para todas as classes e para a classe de interesse (elementos antrópicos) serão utilizados.

	\begin{equation*}
		\displaystyle Pr = \frac{TP}{TP+FP}
	\end{equation*}

	\begin{equation*}
		\displaystyle Rv = \frac{TP}{TP+FN}
	\end{equation*}

	\begin{equation*}
  		\displaystyle F_1 = 2 \cdot \frac{Pr \cdot Rv}{Pr + Rv}
	\end{equation*}
\end{frame}

\begin{frame}[c]
	\frametitle{Metodologia: Classificador - Multiclasse}
	
	Base rotulada e dividida entre 5 classes:
	\vspace{0.3cm}
	\begin{itemize}
		\begin{minipage}{0.4\linewidth}
    		\item Floresta;
			\item Água;
			\item Vegetação rasteira;
		\end{minipage}
		\begin{minipage}{0.4\linewidth}
    		\item Terra;
			\item Elementos antrópicos.
		\end{minipage} 	
	\end{itemize}

	\vspace{0.5cm}
	
	Algoritmos:
	\begin{itemize}
		\item Random Forest;
		\item Árvores de decisão;
		\item KNN;
		\item SVM;
		\item Naive Bayes.
	\end{itemize}\end{frame}

\begin{frame}[c]
	\frametitle{Metodologia: Classificador - Biclasse}

	Base rotulada e dividida entre 2 classes:
	\vspace{0.3cm}
	\begin{itemize}
    	\item Elementos naturais;
		\item Elementos antrópicos.
	\end{itemize}

	\vspace{0.5cm}

	Algoritmos:
	\begin{itemize}
		\item Random Forest;
		\item Árvores de decisão;
		\item KNN;
		\item SVM;
		\item Naive Bayes.
	\end{itemize}

\end{frame}

\begin{frame}[c]
	\frametitle{Metodologia: Classificador - Unário}

	Base dividida em 2 classes, mas parcialmente rotulada para apenas uma classe:
	\vspace{0.3cm}
	\begin{itemize}
    	\item Elementos naturais (target);
    	\item Elementos antrópicos (outlier).
	\end{itemize}

	\vspace{0.5cm}

	Algoritmos:
	\begin{itemize}
		\item OC-SVM;
		\item REPTree.
	\end{itemize}

\end{frame}

\begin{frame}[c]
	\frametitle{Metodologia: Classificador - Conjunto de classificadores}
	
	Diversas bases criadas, uma para cada classificador a ser treinado, levando em consideração a classe de interesse no contexto e a classe anômala.

	\vspace{0.5cm}

	Algoritmos:
	\begin{itemize}
		\item OC-SVM;
		\item REPTree.
	\end{itemize}
	
\end{frame}

\begin{frame}[c]
	\frametitle{Metodologia: Saída}
	\begin{figure}[h]
    	\includegraphics[width=\textwidth]{imgs/arquitetura_5}
	\end{figure}
\end{frame}

\begin{frame}[c]
	\frametitle{Metodologia: Saída}

	O resultado final do processo é uma indicação de quais segmentos da imagem são considerados elementos antrópicos.

	\vspace{0.5cm}	

	A partir do resultado final, pode ser indicado o melhor conjunto de segmentador e classificador para detecção de elementos antrópicos em imagens aéreas da floresta amazônica.

\end{frame}

%%%%%%%%%%%%%%%

\section{Experimentos}

\begin{frame}
	\frametitle{Base de dados}

	\begin{itemize}
		\item 3.044 imagens em cores;
		\item Formato: JPEG;
		\item Nenhum filtro ou tratamento adicional;
		\item Dimensões: 640 x 480 pixels;
		\item 1,02 GB de dados.
	\end{itemize}

	\begin{multicols}{3}
		\begin{figure}
			\includegraphics[scale=0.3]{imgs/amostra1}
		\end{figure}
		\begin{figure}
			\includegraphics[scale=0.3]{imgs/amostra2}
		\end{figure}
		\begin{figure}
			\includegraphics[scale=0.3]{imgs/amostra3}
		\end{figure}
	\end{multicols}

\end{frame}

\begin{frame}
	\frametitle{Segmentação}

	Uma ferramenta\footnote{amazonsegmentation.ddns.net} foi construída para coletar a segmentação manual (ground-truth):
	\begin{itemize}
		\item 31 voluntários;
		\item 5 segmentações por imagem;
		\item 203 imagens diferentes;
	\end{itemize}

	\begin{figure}[h]
  		\centering
		\includegraphics[scale=0.25]{imgs/manualseg}
	\end{figure}

\end{frame}


\begin{frame}[c]
	\frametitle{Segmentação}
	Validação estatística da segmentação manual
	\begin{figure}[h]
		\includegraphics[scale=0.18]{imgs/manual_gce}
	\end{figure}
\end{frame}

\begin{frame}[c]
	\frametitle{Segmentação}
	Validação estatística da segmentação manual
	\begin{figure}[h]
		\includegraphics[scale=0.18]{imgs/manual_lce}
	\end{figure}
\end{frame}


\begin{frame}[c]
	\frametitle{Segmentação}

	\begin{figure}[c]
  		\centering
		\includegraphics[width=0.8\textwidth]{imgs/seg_original}
	\end{figure}

\end{frame}

\begin{frame}[c]
	\frametitle{Segmentação}

	\begin{figure}[c]
		\centering
		\includegraphics[width=\textwidth]{imgs/gambi_apresentacao}
	\end{figure}

\end{frame}

\begin{frame}[c]
	\frametitle{Segmentação}

	Resultados do cálculo dos erros de consistência local e global (Martin et al., 2001) para as 203 imagens utilizadas no benchmark:

	\small{
	\begin{table}[h]
		\begin{tabulary}{\linewidth}{|L|R|R|R|}
		\hline
			\textbf{Algoritmo} & \textbf{GCE médio} & \textbf{LCE médio} & \textbf{Tempo (s)} \\ \hline
			Manual      & 0.01822          & 0.00537         & - \\ \hline
			FSEG        & 0.03063          & 0.00273         & 13,91 \\ \hline
			gPb-owt-ucm & 0.00655          & 0.00297         & 237,32 \\ \hline
			JSEG        & 0.02990          & 0.00486         & 14,82 \\ \hline
			Mean-shift  & 0.02237          & 0.00271         & 6,39 \\ \hline
			MSEG        & 0.01005          & 0.00072         & \cellcolor{gray!25} 0,33 \\ \hline
			SRM         & \cellcolor{gray!25} 0.00622 & \cellcolor{gray!25} 0.00066 & 4,66 \\ \hline
		\end{tabulary}
	\end{table}
	}
\end{frame}

%\begin{frame}
%	\frametitle{Segmentação}
%
%	Um experimento para realizar segmentação e a primeira classificação em uma única etapa foi realizado, um artigo sobre o experimento foi publicado  na conferência VISAPP 2015. 
%
%	\small{
%	\begin{table}
%	\centering
%	\begin{tabulary}{\linewidth}{|L|R|R|}
%		\hline
%		\textbf{Algoritmo} & \textbf{Acurácia} & \textbf{Tempo/imagem} \\ \hline
%		Random forest  & 96,0\% & 12,72 s \\ \hline
%		KNN            & 92,6\% & 22,89 s \\ \hline
%		Naive Bayes    & 92,8\% & 8,36 s \\ \hline
%		Decision tree  & 82,2\% & 14,49 s \\ \hline
%	\end{tabulary}
%	\end{table}
%	}
%
%\end{frame}

\begin{frame}[c]
	\frametitle{Classificação}

	Resultantes da etapa de segmentação com o método SRM, todos os \textbf{10.057} segmentos tiveram características extraídas e foram manualmente rotulados.
	
	\vspace{0.5cm}
	
	\centering
	Vetor de características

	\small{
		\begin{table}[h]
		\centering
		\begin{tabulary}{\linewidth}{|L|L|R|}
		\hline
		\textbf{Atributo} & \textbf{Tipo} & \textbf{Dimensão} \\ \hline
		Vermelho médio            & Real    &  1x1 \\ \hline
		Verde médio               & Real    &  1x1 \\ \hline
		Azul médio                & Real    &  1x1 \\ \hline
		Intensidade média         & Real    &  1x1 \\ \hline
		Intensidade - histograma  & Inteiro & 16x1 \\ \hline
		LBP - histograma          & Inteiro & 26x1 \\ \hline
		Hough - número de retas   & Inteiro &  1x1 \\ \hline
		Hough - maior reta        & Inteiro &  1x1 \\ \hline
		\end{tabulary}
		\end{table}
	}

\end{frame}

\begin{frame}[c]
	\frametitle{Classificação}

	\centering
	Distribuição de classes

	\small{
	\begin{table}[h]
	\centering
	\begin{tabulary}{\linewidth}{|L|R|R|}
		\hline
		\textbf{Classe} & \textbf{Amostras} & \textbf{Percentual} \\ \hline
		Floresta             & 8.686 & 86,36\% \\ \hline
		Vegetação rasteira   & 944   &  9,38\% \\ \hline
		Água                 & 287   &  2,85\% \\ \hline
		Clareira             & 136   &  1,35\% \\ \hline
		Elementos antrópicos & 24    &  0,23\% \\ \hline
	\end{tabulary}
	\end{table}
	}
	\centering
	Base disponível em \textbf{github.com/luizcavalcanti/geoma-database}.

\end{frame}

\begin{frame}
	\frametitle{Classificação - Multiclasse}

	Vetor de características do segmento:
	\begin{itemize}
		\item Cor média dos canais R, G e B;
 		\item Grayscale médio;
		\item Histograma grayscale.
		\item Histograma de Local Binary Patterns
	\end{itemize}

	\small{
	\begin{table}[h]
	\centering
	\begin{tabulary}{\linewidth}{|L|L|R|}
	\hline
	\textbf{Atributo} & \textbf{Tipo} & \textbf{Dimensão} \\ \hline
	Intensidade - histograma (5/15) & Inteiro & 5x1 \\ \hline
	LBP - histograma (1/26)         & Inteiro & 1x1 \\ \hline
	Hough - maior reta              & Inteiro & 1x1 \\ \hline
	\end{tabulary}
	\caption{Atributos selecionados pela técnica de CFS para a abordagem de classificação multi-classe}
	\label{tab:experimentoMulticlasseAtributosFiltrados}
	\end{table}
	}

\end{frame}

\begin{frame}
	\frametitle{Próximos passos}

	\begin{itemize}
		\item Melhorar precisão da classe de elementos antrópicos;
		\item Incluir morfologia no vetor de características;
		\item Produzir elementos antrópicos em amostrar para próxima fase de classificação;
		\item Realizar experimentos com classificadores unitários.
	\end{itemize}

\end{frame}
%%%%%%%%%%%%%%%

\section{Conclusão}

\begin{frame}[c]
	\frametitle{Cronograma}
	\begin{table}[h]
	\resizebox{\textwidth}{!}{%
	\begin{tabular}{|l|c|c|c|c|c|c|c|c|c|c|c|c|}
		\hline
		Atividade/Mês & 02/14 & 03/14 & 04/14 & 05/14 & 06/14 & 07/14 & 08/14 & 09/14 & 10/14 & 11/14 & 12/14 & 01/14 \\ \hline
		Disciplinas & \cellcolor{blue!25} & \cellcolor{blue!25} & \cellcolor{blue!25} & \cellcolor{blue!25} & \cellcolor{blue!25} & \cellcolor{blue!25} & \cellcolor{blue!25} & \cellcolor{blue!25} & \cellcolor{blue!25} & \cellcolor{blue!25} & \cellcolor{blue!25} & \cellcolor{blue!25} \\ \hline
		Levantamento &  &  &  & \cellcolor{blue!25} & \cellcolor{blue!25} & \cellcolor{blue!25} & \cellcolor{blue!25} &  &  &  &  &  \\ \hline
		Experimentos &  &  &  &  &  &  & \cellcolor{blue!25} & \cellcolor{blue!25} & \cellcolor{blue!25} & \cellcolor{blue!25} & \cellcolor{blue!25} & \cellcolor{blue!25} \\ \hline
	\end{tabular}
	}
	\end{table}

	\begin{table}[h]
	\resizebox{\textwidth}{!}{%
	\begin{tabular}{|l|c|c|c|c|c|c|c|c|c|c|c|c|}
		\hline
		Atividade/Mês & 02/15 & 03/15 & 04/15 & 05/15 & 06/15 & 07/15 & 08/15 & 09/15 & 10/15 & 11/15 & 12/15 & 01/16 \\ \hline
		Experimentos & \cellcolor{blue!25} & \cellcolor{blue!25} & \cellcolor{blue!25} & \cellcolor{blue!25} & \cellcolor{blue!25} & \cellcolor{blue!25} & \cellcolor{blue!25} & \cellcolor{blue!25} & \cellcolor{blue!25} & \cellcolor{blue!25} & \cellcolor{blue!25} & \cellcolor{blue!25} \\ \hline
		Sub. de artigos & & & & \cellcolor{blue!25} & \cellcolor{blue!25} & \cellcolor{blue!25} & \cellcolor{blue!25} &  &  &  &  &  \\ \hline
		Dissertação &  &  &  & \cellcolor{blue!25} & \cellcolor{blue!25} & \cellcolor{blue!25} & \cellcolor{blue!25} & \cellcolor{blue!25} & \cellcolor{blue!25} & \cellcolor{blue!25} & \cellcolor{blue!25} & \cellcolor{blue!25} \\ \hline
	\end{tabular}
	}
	\end{table}

\end{frame}

\section{Trabalhos futuros}


%\section{Bibliografia}

%\begin{frame}{Referências}
%	\tiny{\bibliographystyle{abbrv}}
%	\tiny{\bibliographystyle{apacite}}
%	\bibliographystyle{humannat}
%	\bibliography{qualificacao}
%\end{frame}

\end{document}